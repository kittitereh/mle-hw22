{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d00984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5dd3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.feature import IDF\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784584e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300839b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a4c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 15:31:09 WARN Utils: Your hostname, kittitereh resolves to a loopback address: 127.0.1.1; using 192.168.182.221 instead (on interface wlp2s0)\n",
      "23/02/03 15:31:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 15:31:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"TFIDF\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb42c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.182.221:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TFIDF</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=TFIDF>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b4e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ab892ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.182.221:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TFIDF</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2dbb56d210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b652435",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load('trainx16x32_0.npz')['arr_0'][:10000]\n",
    "test_data = load('testx16x32_0.npz')['arr_0'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1bdf443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe6e2c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f99e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa642e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>23846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15</td>\n",
       "      <td>115548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15</td>\n",
       "      <td>115549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15</td>\n",
       "      <td>115757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15</td>\n",
       "      <td>115826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15</td>\n",
       "      <td>115840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1\n",
       "0      0   16981\n",
       "1      0   23846\n",
       "2      0   27947\n",
       "3      0   31189\n",
       "4      0   31713\n",
       "...   ..     ...\n",
       "9995  15  115548\n",
       "9996  15  115549\n",
       "9997  15  115757\n",
       "9998  15  115826\n",
       "9999  15  115840\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e76615fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    int64\n",
       "1    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4c0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "mySchema = StructType([ StructField(\"user\", IntegerType(), True),StructField(\"film\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f71e8313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|user| film|\n",
      "+----+-----+\n",
      "|   0|16981|\n",
      "|   0|23846|\n",
      "|   0|27947|\n",
      "|   0|31189|\n",
      "|   0|31713|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train = spark.createDataFrame(train_df, schema=mySchema)\n",
    "test = spark.createDataFrame(test_df, schema=mySchema)\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c845bb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b0ccc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- film: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3107e74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 3, 5, 4, 6, 8, 7, 9, 10, 11, 12, 13, 15, 14]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find unique users\n",
    "train.select('user').distinct().rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c010ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  film|count|\n",
      "+------+-----+\n",
      "|227972|    8|\n",
      "|189191|    8|\n",
      "|191991|    7|\n",
      "|388742|    7|\n",
      "|236360|    6|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "films_counted = train.groupBy('film').count()\n",
    "# find the most watched films\n",
    "films_counted.orderBy(col(\"count\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba520e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|film|collect_list(user)|\n",
      "+----+------------------+\n",
      "|  27|               [4]|\n",
      "|1169|               [7]|\n",
      "|1218|               [3]|\n",
      "|1352|               [9]|\n",
      "|1937|               [2]|\n",
      "+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "films_by_users= train.groupBy(\"film\").agg(collect_list(\"user\"))\n",
    "films_by_users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53182fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+--------------------+\n",
      "|film|collect_list(user)|                  tf|\n",
      "+----+------------------+--------------------+\n",
      "|  27|               [4]|(10000,[5102],[1.0])|\n",
      "|1169|               [7]|(10000,[3707],[1.0])|\n",
      "|1218|               [3]|(10000,[8051],[1.0])|\n",
      "|1352|               [9]|(10000,[8889],[1.0])|\n",
      "|1937|               [2]|(10000,[1574],[1.0])|\n",
      "|2500|               [2]|(10000,[1574],[1.0])|\n",
      "|2953|              [12]|(10000,[1024],[1.0])|\n",
      "|3171|              [12]|(10000,[1024],[1.0])|\n",
      "|3494|              [13]|(10000,[8648],[1.0])|\n",
      "|3606|               [3]|(10000,[8051],[1.0])|\n",
      "|3613|              [15]|(10000,[6477],[1.0])|\n",
      "|4176|               [7]|(10000,[3707],[1.0])|\n",
      "|4437|               [2]|(10000,[1574],[1.0])|\n",
      "|4772|               [5]|(10000,[6466],[1.0])|\n",
      "|5031|               [9]|(10000,[8889],[1.0])|\n",
      "|7306|               [5]|(10000,[6466],[1.0])|\n",
      "|7367|               [7]|(10000,[3707],[1.0])|\n",
      "|7453|               [7]|(10000,[3707],[1.0])|\n",
      "|7480|               [7]|(10000,[3707],[1.0])|\n",
      "|7645|              [11]|(10000,[5163],[1.0])|\n",
      "+----+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"collect_list(user)\", outputCol=\"tf\",numFeatures=10000, )\n",
    "tf = hashingTF.transform(films_by_users)\n",
    "tf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05ae1aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+--------------------+-----------------------------------+\n",
      "|film|collect_list(user)|tf                  |idf                                |\n",
      "+----+------------------+--------------------+-----------------------------------+\n",
      "|27  |[4]               |(10000,[5102],[1.0])|(10000,[5102],[2.8348152173579018])|\n",
      "|1169|[7]               |(10000,[3707],[1.0])|(10000,[3707],[2.496547648118015]) |\n",
      "|1218|[3]               |(10000,[8051],[1.0])|(10000,[8051],[2.2099872807754335])|\n",
      "|1352|[9]               |(10000,[8889],[1.0])|(10000,[8889],[2.1575162290379803])|\n",
      "|1937|[2]               |(10000,[1574],[1.0])|(10000,[1574],[2.4286515412855976])|\n",
      "|2500|[2]               |(10000,[1574],[1.0])|(10000,[1574],[2.4286515412855976])|\n",
      "|2953|[12]              |(10000,[1024],[1.0])|(10000,[1024],[2.362455874419707]) |\n",
      "|3171|[12]              |(10000,[1024],[1.0])|(10000,[1024],[2.362455874419707]) |\n",
      "|3494|[13]              |(10000,[8648],[1.0])|(10000,[8648],[2.3379226878958352])|\n",
      "|3606|[3]               |(10000,[8051],[1.0])|(10000,[8051],[2.2099872807754335])|\n",
      "|3613|[15]              |(10000,[6477],[1.0])|(10000,[6477],[4.127134385045092]) |\n",
      "|4176|[7]               |(10000,[3707],[1.0])|(10000,[3707],[2.496547648118015]) |\n",
      "|4437|[2]               |(10000,[1574],[1.0])|(10000,[1574],[2.4286515412855976])|\n",
      "|4772|[5]               |(10000,[6466],[1.0])|(10000,[6466],[2.7089124293997617])|\n",
      "|5031|[9]               |(10000,[8889],[1.0])|(10000,[8889],[2.1575162290379803])|\n",
      "|7306|[5]               |(10000,[6466],[1.0])|(10000,[6466],[2.7089124293997617])|\n",
      "|7367|[7]               |(10000,[3707],[1.0])|(10000,[3707],[2.496547648118015]) |\n",
      "|7453|[7]               |(10000,[3707],[1.0])|(10000,[3707],[2.496547648118015]) |\n",
      "|7480|[7]               |(10000,[3707],[1.0])|(10000,[3707],[2.496547648118015]) |\n",
      "|7645|[11]              |(10000,[5163],[1.0])|(10000,[5163],[2.5207545789698123])|\n",
      "+----+------------------+--------------------+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"tf\", outputCol=\"idf\")\n",
    "tfidf = idf.fit(tf).transform(tf)\n",
    "tfidf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a52febb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute L2 norm\n",
    "\n",
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = Normalizer(inputCol=\"idf\", outputCol=\"norm\")\n",
    "data = normalizer.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a893b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+--------------------+--------------------+--------------------+\n",
      "|film|collect_list(user)|                  tf|                 idf|                norm|\n",
      "+----+------------------+--------------------+--------------------+--------------------+\n",
      "|  27|               [4]|(10000,[5102],[1.0])|(10000,[5102],[2....|(10000,[5102],[1.0])|\n",
      "|1169|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....|(10000,[3707],[1.0])|\n",
      "|1218|               [3]|(10000,[8051],[1.0])|(10000,[8051],[2....|(10000,[8051],[1.0])|\n",
      "|1352|               [9]|(10000,[8889],[1.0])|(10000,[8889],[2....|(10000,[8889],[1.0])|\n",
      "|1937|               [2]|(10000,[1574],[1.0])|(10000,[1574],[2....|(10000,[1574],[1.0])|\n",
      "|2500|               [2]|(10000,[1574],[1.0])|(10000,[1574],[2....|(10000,[1574],[1.0])|\n",
      "|2953|              [12]|(10000,[1024],[1.0])|(10000,[1024],[2....|(10000,[1024],[1.0])|\n",
      "|3171|              [12]|(10000,[1024],[1.0])|(10000,[1024],[2....|(10000,[1024],[1.0])|\n",
      "|3494|              [13]|(10000,[8648],[1.0])|(10000,[8648],[2....|(10000,[8648],[1.0])|\n",
      "|3606|               [3]|(10000,[8051],[1.0])|(10000,[8051],[2....|(10000,[8051],[1.0])|\n",
      "|3613|              [15]|(10000,[6477],[1.0])|(10000,[6477],[4....|(10000,[6477],[1.0])|\n",
      "|4176|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....|(10000,[3707],[1.0])|\n",
      "|4437|               [2]|(10000,[1574],[1.0])|(10000,[1574],[2....|(10000,[1574],[1.0])|\n",
      "|4772|               [5]|(10000,[6466],[1.0])|(10000,[6466],[2....|(10000,[6466],[1.0])|\n",
      "|5031|               [9]|(10000,[8889],[1.0])|(10000,[8889],[2....|(10000,[8889],[1.0])|\n",
      "|7306|               [5]|(10000,[6466],[1.0])|(10000,[6466],[2....|(10000,[6466],[1.0])|\n",
      "|7367|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....|(10000,[3707],[1.0])|\n",
      "|7453|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....|(10000,[3707],[1.0])|\n",
      "|7480|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....|(10000,[3707],[1.0])|\n",
      "|7645|              [11]|(10000,[5163],[1.0])|(10000,[5163],[2....|(10000,[5163],[1.0])|\n",
      "+----+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a5b39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply the table with itself to get the cosine similarity as the dot product of two by two L2norms\n",
    "import pyspark.sql.functions as psf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "dot_udf = psf.udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "res = data.alias(\"i\").join(data.alias(\"j\"), psf.col(\"i.film\") < psf.col(\"j.film\"))\\\n",
    "    .select(\n",
    "        psf.col(\"i.film\").alias(\"i\"), \n",
    "        psf.col(\"j.film\").alias(\"j\"), \n",
    "        dot_udf(\"i.norm\", \"j.norm\").alias(\"dot\"))\\\n",
    "    .sort(\"i\", \"j\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "819fefe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 15:49:20 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_91_0 in memory.\n",
      "23/02/03 15:49:20 WARN MemoryStore: Not enough space to cache rdd_91_0 in memory! (computed 384.0 B so far)\n",
      "23/02/03 15:49:20 WARN BlockManager: Block rdd_91_0 could not be removed as it was not found on disk or in memory\n",
      "23/02/03 15:49:20 WARN BlockManager: Putting block rdd_91_0 failed\n",
      "23/02/03 15:49:35 ERROR Executor: Exception in task 0.0 in stage 34.0 (TID 85)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix.$anonfun$toBlockMatrix$7(IndexedRowMatrix.scala:159)\n",
      "\tat org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix$$Lambda$3833/0x000000084136e040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n",
      "\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat scala.collection.AbstractIterator.to(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3000/0x0000000841262840.apply(Unknown Source)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)\n",
      "\tat org.apache.spark.SparkContext$$Lambda$2394/0x0000000841067040.apply(Unknown Source)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2348/0x0000000841014c40.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "23/02/03 15:49:35 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 34.0 (TID 85),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix.$anonfun$toBlockMatrix$7(IndexedRowMatrix.scala:159)\n",
      "\tat org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix$$Lambda$3833/0x000000084136e040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n",
      "\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat scala.collection.AbstractIterator.to(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3000/0x0000000841262840.apply(Unknown Source)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)\n",
      "\tat org.apache.spark.SparkContext$$Lambda$2394/0x0000000841067040.apply(Unknown Source)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2348/0x0000000841014c40.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "23/02/03 15:49:35 WARN TaskSetManager: Lost task 0.0 in stage 34.0 (TID 85) (192.168.182.221 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix.$anonfun$toBlockMatrix$7(IndexedRowMatrix.scala:159)\n",
      "\tat org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix$$Lambda$3833/0x000000084136e040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:783)\n",
      "\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat scala.collection.AbstractIterator.to(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$3000/0x0000000841262840.apply(Unknown Source)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2268)\n",
      "\tat org.apache.spark.SparkContext$$Lambda$2394/0x0000000841067040.apply(Unknown Source)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2348/0x0000000841014c40.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\n",
      "23/02/03 15:49:35 ERROR TaskSetManager: Task 0 in stage 34.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 57612)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_149635/3891694691.py\", line 5, in <module>\n",
      "    dot = mat.multiply(mat.transpose())\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/mllib/linalg/distributed.py\", line 1547, in multiply\n",
      "    java_block_matrix = self._java_matrix_wrapper.call(\"multiply\", other_java_block_matrix)\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/mllib/common.py\", line 157, in call\n",
      "    return callJavaFunc(self._sc, getattr(self._java_model, name), *a)\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/mllib/common.py\", line 131, in callJavaFunc\n",
      "    return _java2py(sc, func(*java_args))\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/kittitereh/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn [30], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m mat \u001b[38;5;241m=\u001b[39m IndexedRowMatrix(\n\u001b[1;32m      3\u001b[0m     data\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: IndexedRow(row\u001b[38;5;241m.\u001b[39mfilm, row\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mtoArray())))\u001b[38;5;241m.\u001b[39mtoBlockMatrix()\n\u001b[0;32m----> 5\u001b[0m dot \u001b[38;5;241m=\u001b[39m \u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/mllib/linalg/distributed.py:1547\u001b[0m, in \u001b[0;36mBlockMatrix.multiply\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1546\u001b[0m other_java_block_matrix \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_java_matrix_wrapper\u001b[38;5;241m.\u001b[39m_java_model\n\u001b[0;32m-> 1547\u001b[0m java_block_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_matrix_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultiply\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_java_block_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BlockMatrix(java_block_matrix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowsPerBlock, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolsPerBlock)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/mllib/common.py:157\u001b[0m, in \u001b[0;36mJavaModelWrapper.call\u001b[0;34m(self, name, *a)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"Call method of java_model\"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallJavaFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/mllib/common.py:131\u001b[0m, in \u001b[0;36mcallJavaFunc\u001b[0;34m(sc, func, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m java_args \u001b[38;5;241m=\u001b[39m [_py2java(sc, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _java2py(sc, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjava_args\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2063\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m   2061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2063\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[1;32m   2065\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2066\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py:538\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    532\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    533\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    535\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    539\u001b[0m }\n\u001b[1;32m    541\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[0;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "mat = IndexedRowMatrix(\n",
    "    data.select(\"film\", \"norm\")\\\n",
    "        .rdd.map(lambda row: IndexedRow(row.film, row.norm.toArray()))).toBlockMatrix()\n",
    "dot = mat.multiply(mat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208960b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8362a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tfidf.rdd.map(lambda x : (x.film, x[\"collect_list(user)\"], x.tf, x.idf,(None if x.idf is None else x.idf.values.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c39a581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, [4], SparseVector(10000, {5102: 1.0}), SparseVector(10000, {5102: 2.8348}), 2.8348152173579018)\n",
      "(1169, [7], SparseVector(10000, {3707: 1.0}), SparseVector(10000, {3707: 2.4965}), 2.496547648118015)\n",
      "(1218, [3], SparseVector(10000, {8051: 1.0}), SparseVector(10000, {8051: 2.21}), 2.2099872807754335)\n",
      "(1352, [9], SparseVector(10000, {8889: 1.0}), SparseVector(10000, {8889: 2.1575}), 2.1575162290379803)\n",
      "(1937, [2], SparseVector(10000, {1574: 1.0}), SparseVector(10000, {1574: 2.4287}), 2.4286515412855976)\n",
      "(2500, [2], SparseVector(10000, {1574: 1.0}), SparseVector(10000, {1574: 2.4287}), 2.4286515412855976)\n",
      "(2953, [12], SparseVector(10000, {1024: 1.0}), SparseVector(10000, {1024: 2.3625}), 2.362455874419707)\n",
      "(3171, [12], SparseVector(10000, {1024: 1.0}), SparseVector(10000, {1024: 2.3625}), 2.362455874419707)\n",
      "(3494, [13], SparseVector(10000, {8648: 1.0}), SparseVector(10000, {8648: 2.3379}), 2.3379226878958352)\n",
      "(3606, [3], SparseVector(10000, {8051: 1.0}), SparseVector(10000, {8051: 2.21}), 2.2099872807754335)\n"
     ]
    }
   ],
   "source": [
    "for r in res.take(10):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e7dd7238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+--------------------+--------------------+------------------+\n",
      "|film|collect_list(user)|                  tf|                 idf|           idf_sum|\n",
      "+----+------------------+--------------------+--------------------+------------------+\n",
      "|  27|               [4]|(10000,[5102],[1.0])|(10000,[5102],[2....|2.8348152173579018|\n",
      "|1169|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....| 2.496547648118015|\n",
      "|1218|               [3]|(10000,[8051],[1.0])|(10000,[8051],[2....|2.2099872807754335|\n",
      "|1352|               [9]|(10000,[8889],[1.0])|(10000,[8889],[2....|2.1575162290379803|\n",
      "|1937|               [2]|(10000,[1574],[1.0])|(10000,[1574],[2....|2.4286515412855976|\n",
      "|2500|               [2]|(10000,[1574],[1.0])|(10000,[1574],[2....|2.4286515412855976|\n",
      "|2953|              [12]|(10000,[1024],[1.0])|(10000,[1024],[2....| 2.362455874419707|\n",
      "|3171|              [12]|(10000,[1024],[1.0])|(10000,[1024],[2....| 2.362455874419707|\n",
      "|3494|              [13]|(10000,[8648],[1.0])|(10000,[8648],[2....|2.3379226878958352|\n",
      "|3606|               [3]|(10000,[8051],[1.0])|(10000,[8051],[2....|2.2099872807754335|\n",
      "|3613|              [15]|(10000,[6477],[1.0])|(10000,[6477],[4....| 4.127134385045092|\n",
      "|4176|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....| 2.496547648118015|\n",
      "|4437|               [2]|(10000,[1574],[1.0])|(10000,[1574],[2....|2.4286515412855976|\n",
      "|4772|               [5]|(10000,[6466],[1.0])|(10000,[6466],[2....|2.7089124293997617|\n",
      "|5031|               [9]|(10000,[8889],[1.0])|(10000,[8889],[2....|2.1575162290379803|\n",
      "|7306|               [5]|(10000,[6466],[1.0])|(10000,[6466],[2....|2.7089124293997617|\n",
      "|7367|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....| 2.496547648118015|\n",
      "|7453|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....| 2.496547648118015|\n",
      "|7480|               [7]|(10000,[3707],[1.0])|(10000,[3707],[2....| 2.496547648118015|\n",
      "|7645|              [11]|(10000,[5163],[1.0])|(10000,[5163],[2....|2.5207545789698123|\n",
      "+----+------------------+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 173:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "sum_ = udf(lambda v: float(v.values.sum()), DoubleType())\n",
    "tfidf.withColumn(\"idf_sum\", sum_(\"idf\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced509e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc72e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
